{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b00ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat as py\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dfeb054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# import dask\n",
    "# import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e439be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= py.read_sav('/Users/radhika/Google Drive Stanford/IRW/PISA/2015/CY6_MS_CMB_STU_COG.sav')\n",
    "pisa_full =data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94686149",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keep columns we want\n",
    "#ext = [\"A\", \"F\", \"B\", \"C\", \"D\", \"E\"]\n",
    "ext2= [\"S\", \"T\"]\n",
    "ext3= [\"T\"]\n",
    "start1=[\"CR\", \"DR\", \"PR\", \"R\"]\n",
    "start2=[\"CM\", \"DM\"]\n",
    "start3=[\"CS\", \"DS\", \"PS\"]\n",
    "start4=[\"CC\"]\n",
    "#startnames= [\"CR\", \"CM\"]\n",
    "\n",
    "col_names_read = pisa_full.columns[pisa_full.columns.str.startswith(tuple(start1))]\n",
    "col_names2=  list(col_names_read[col_names_read.str.endswith(tuple(ext2))])\n",
    "col_names_id= ['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID']\n",
    "col_names2.extend(col_names_id)\n",
    "colnames_exclude= ['Option_CPS','CYC', 'VER_DAT']\n",
    "col_names_subset_score_read = list(set(col_names2) - set(colnames_exclude))\n",
    "\n",
    "### MATH\n",
    "col_names_math = pisa_full.columns[pisa_full.columns.str.startswith(tuple(start2))]\n",
    "col_names2=  list(col_names_math[col_names_math.str.endswith(tuple(ext2))])\n",
    "col_names_id= ['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID']\n",
    "col_names2.extend(col_names_id)\n",
    "colnames_exclude= ['Option_CPS','CYC', 'VER_DAT']\n",
    "col_names_subset_score_math = list(set(col_names2) - set(colnames_exclude))\n",
    "\n",
    "## SCIENCE\n",
    "col_names_science = pisa_full.columns[pisa_full.columns.str.startswith(tuple(start3))]\n",
    "col_names2=  list(col_names_science[col_names_science.str.endswith(tuple(ext2))])\n",
    "col_names_id= ['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID']\n",
    "col_names2.extend(col_names_id)\n",
    "colnames_exclude= ['Option_CPS','CYC', 'VER_DAT']\n",
    "col_names_subset_score_science = list(set(col_names2) - set(colnames_exclude))\n",
    "\n",
    "## PROBLEM SOLVING\n",
    "# col_names_ps = pisa_full.columns[pisa_full.columns.str.startswith(tuple(start4))]\n",
    "# col_names2=  list(col_names_ps[col_names_ps.str.endswith(tuple(ext2))])\n",
    "# col_names_id= ['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID']\n",
    "# col_names2.extend(col_names_id)\n",
    "# colnames_exclude= ['Option_CPS','CYC', 'VER_DAT']\n",
    "# col_names_subset_score_ps = list(set(col_names2) - set(colnames_exclude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de57a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_subset=col_names_subset_score_ps\n",
    "pisa_subset = pisa_full[col_names_subset]\n",
    "pisa_long = pisa_subset.melt(id_vars= ['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID'], var_name='item', value_name=\"resp_text\")\n",
    "pisa_long['resp_type'] = pisa_long['item'].str[-1:]\n",
    "pisa_long['resp_type'] = np.where(pisa_long['resp_type'] ==\"C\", \"S\", pisa_long['resp_type'])\n",
    "# pisa_long = pisa_long[~pd.isnull(pisa_long['resp_text'])]\n",
    "# pisa_long['item'] = pisa_long['item'].str[:-1]\n",
    "#pisa_wide= pisa_long.pivot(index=['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID','item'], columns='resp_type', values='resp_text').reset_index()\n",
    "# pisa_wide=pisa_wide.rename(columns={'S': 'resp', 'T': 'rt'})\n",
    "# filename=\"/Users/radhika/Google Drive Stanford/IRW/PISA/2015/pisa2015_\" + str(subject) + \".csv\"\n",
    "# pisa_wide.to_csv(filename, index=False) #single_file=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c69961d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9576d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasubset_fnc(pisa_full, col_names_subset, subject):\n",
    "    pisa_subset = pisa_full[col_names_subset]\n",
    "    pisa_long = pisa_subset.melt(id_vars= ['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID'], var_name='item', value_name=\"resp_text\")\n",
    "    pisa_long['resp_type'] = pisa_long['item'].str[-1:]\n",
    "    #pisa_long['resp_type'] = np.where(pisa_long['resp_type'] ==\"C\", \"S\", pisa_long['resp_type'])\n",
    "    #pisa_long = pisa_long[~pd.isnull(pisa_long['resp_text'])]\n",
    "    pisa_long['item'] = pisa_long['item'].str[:-1]\n",
    "    pisa_wide= pisa_long.pivot(index=['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID','item'], columns='resp_type', values='resp_text').reset_index()\n",
    "    pisa_wide=pisa_wide.rename(columns={'S': 'resp', 'T': 'rt', 'CNTSTUID':'id'})\n",
    "    pisa_wide['rt']/=1000\n",
    "    filename=\"/Users/radhika/Google Drive Stanford/IRW/PISA/2015/pisa2015_\" + str(subject) + \".csv\"\n",
    "    pisa_wide.to_csv(filename, index=False) #single_file=True,\n",
    "    #pisa_read2 = pisa_read.unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasubset_fnc(pisa_full,col_names_subset_score_math, \"math\")\n",
    "#datasubset_fnc(pisa_full,col_names_subset_score_science, \"science\")\n",
    "datasubset_fnc(pisa_full,col_names_subset_score_read, \"read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c9446b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa9ed57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbe48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###STUDENT DATA\n",
    "data2= py.read_sav('/Users/radhika/Google Drive Stanford/IRW/PISA/2015/CY6_MS_CMB_STU_COG.sav')\n",
    "pisa_full =data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= pd.merge(pisa_long_time, pisa_long_score, on=['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155384d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape\n",
    "# from functools import reduce\n",
    "\n",
    "# #create a list that contains all your data frames to be merged\n",
    "# ldf = [pisa_long_time,pisa_long_score]\n",
    "# #necessary to have a common name column to merge all the frames\n",
    "# df = reduce(lambda x,y: pd.merge(x,y, on = ['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID'], how = \"left\"), ldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fbb6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have already imported and created df1 and df2\n",
    "# #partition_freq = '50MB'\n",
    "# # Convert pandas DataFrames to Dask DataFrames\n",
    "# ddf1 = dd.from_pandas(pisa_long_time,  npartitions=4)\n",
    "# ddf2 = dd.from_pandas(pisa_long_score, npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0f48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Perform the merge operation\n",
    "# ddf = dd.merge(ddf1, ddf2, on=['CNTRYID', 'CNT', 'CNTSCHID', 'CNTSTUID'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf.to_csv(\"/Users/radhika/Google Drive Stanford/IRW/PISA/2015/pisa2015.csv\", index=False) #single_file=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute the result and convert back to a pandas DataFrame\n",
    "# ddf.compute().to_csv(\"/Users/radhika/Google Drive Stanford/IRW/PISA/2015/pisa2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# col_names1_stub = [x[:-1] for x in col_names1]\n",
    "# col_names1_stub = np.unique(col_names1_stub)\n",
    "# col_names1_stub= list(col_names1_stub)\n",
    "# #print(col_names1_stub)\n",
    "# #pisa_subset = pisa_full[pisa_full.columns[~pisa_full.columns.str.endswith(tuple(ext))]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
